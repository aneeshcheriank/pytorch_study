{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a97ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc02b710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = [[1.80416086]]\n",
      "epoch: 1, w = [0.7898605], loss = 3.51624713456356\n",
      "epoch: 2, w = [1.1065969], loss = 1.9164761725578345\n",
      "epoch: 3, w = [1.34043216], loss = 1.0445457271415046\n",
      "epoch: 4, w = [1.51306445], loss = 0.5693135097178723\n",
      "epoch: 5, w = [1.64051274], loss = 0.31029553223510864\n",
      "epoch: 6, w = [1.7346033], loss = 0.16912178559188457\n",
      "epoch: 7, w = [1.80406702], loss = 0.0921772162034087\n",
      "epoch: 8, w = [1.85534963], loss = 0.050239767498160046\n",
      "epoch: 9, w = [1.89320976], loss = 0.027382409040205287\n",
      "epoch: 10, w = [1.92116055], loss = 0.014924358972652074\n",
      "epoch: 11, w = [1.94179563], loss = 0.00813429126770909\n",
      "epoch: 12, w = [1.95702978], loss = 0.004433469775765525\n",
      "epoch: 13, w = [1.96827661], loss = 0.0024163942015027183\n",
      "epoch: 14, w = [1.97657974], loss = 0.0013170183247832763\n",
      "epoch: 15, w = [1.98270965], loss = 0.0007178204891967806\n",
      "epoch: 16, w = [1.98723515], loss = 0.00039123696687781603\n",
      "epoch: 17, w = [1.99057616], loss = 0.00021323766394997683\n",
      "epoch: 18, w = [1.99304272], loss = 0.00011622189408559396\n",
      "epoch: 19, w = [1.99486368], loss = 6.334494767308985e-05\n",
      "epoch: 20, w = [1.99620804], loss = 3.452518501162384e-05\n",
      "epoch: 21, w = [1.99720053], loss = 1.8817418655682875e-05\n",
      "epoch: 22, w = [1.99793325], loss = 1.0256143297827515e-05\n",
      "epoch: 23, w = [1.99847419], loss = 5.589952440890296e-06\n",
      "epoch: 24, w = [1.99887355], loss = 3.0467172097750174e-06\n",
      "epoch: 25, w = [1.99916838], loss = 1.6605661415719176e-06\n",
      "epoch: 26, w = [1.99938605], loss = 9.050659187166477e-07\n",
      "epoch: 27, w = [1.99954674], loss = 4.932921951829978e-07\n",
      "epoch: 28, w = [1.99966537], loss = 2.688612893230561e-07\n",
      "epoch: 29, w = [1.99975296], loss = 1.4653869167671678e-07\n",
      "epoch: 30, w = [1.99981762], loss = 7.98686497872909e-08\n",
      "epoch: 31, w = [1.99986535], loss = 4.353117354788884e-08\n",
      "epoch: 32, w = [1.9999006], loss = 2.3725993559383905e-08\n",
      "epoch: 33, w = [1.99992661], loss = 1.2931486208669527e-08\n",
      "epoch: 34, w = [1.99994582], loss = 7.048106758769205e-09\n",
      "epoch: 35, w = [1.99996], loss = 3.841461691383161e-09\n",
      "epoch: 36, w = [1.99997047], loss = 2.0937293420000296e-09\n",
      "epoch: 37, w = [1.9999782], loss = 1.1411548284702611e-09\n",
      "epoch: 38, w = [1.99998391], loss = 6.219688077313781e-10\n",
      "epoch: 39, w = [1.99998812], loss = 3.389944888597582e-10\n",
      "epoch: 40, w = [1.99999123], loss = 1.8476370848390612e-10\n",
      "epoch: 41, w = [1.99999352], loss = 1.0070260459988674e-10\n",
      "epoch: 42, w = [1.99999522], loss = 5.48863987214287e-11\n",
      "epoch: 43, w = [1.99999647], loss = 2.991498359377889e-11\n",
      "epoch: 44, w = [1.99999739], loss = 1.630469960335987e-11\n",
      "epoch: 45, w = [1.99999808], loss = 8.886624601575234e-12\n",
      "epoch: 46, w = [1.99999858], loss = 4.843517435601368e-12\n",
      "epoch: 47, w = [1.99999895], loss = 2.6398843433472694e-12\n",
      "epoch: 48, w = [1.99999923], loss = 1.4388281736247628e-12\n",
      "epoch: 49, w = [1.99999943], loss = 7.842110652248286e-13\n",
      "epoch: 50, w = [1.99999958], loss = 4.274221245626124e-13\n",
      "epoch: 51, w = [1.99999969], loss = 2.3295982516373233e-13\n",
      "epoch: 52, w = [1.99999977], loss = 1.2697115329026462e-13\n",
      "epoch: 53, w = [1.99999983], loss = 6.920366538985839e-14\n",
      "epoch: 54, w = [1.99999987], loss = 3.771838860673196e-14\n",
      "epoch: 55, w = [1.99999991], loss = 2.0557824950726372e-14\n",
      "epoch: 56, w = [1.99999993], loss = 1.1204724851876016e-14\n",
      "epoch: 57, w = [1.99999995], loss = 6.106962161458628e-15\n",
      "epoch: 58, w = [1.99999996], loss = 3.3285053729120037e-15\n",
      "epoch: 59, w = [1.99999997], loss = 1.8141504352167944e-15\n",
      "epoch: 60, w = [1.99999998], loss = 9.88774665723173e-16\n",
      "epoch: 61, w = [1.99999999], loss = 5.389163504152233e-16\n",
      "epoch: 62, w = [1.99999999], loss = 2.9372802734087103e-16\n",
      "epoch: 63, w = [1.99999999], loss = 1.600919207698599e-16\n",
      "epoch: 64, w = [1.99999999], loss = 8.725562681027322e-17\n",
      "epoch: 65, w = [2.], loss = 4.7557331789801545e-17\n",
      "epoch: 66, w = [2.], loss = 2.5920387484262504e-17\n",
      "epoch: 67, w = [2.], loss = 1.4127506159472218e-17\n",
      "epoch: 68, w = [2.], loss = 7.699979712420861e-18\n",
      "epoch: 69, w = [2.], loss = 4.196755539304729e-18\n",
      "epoch: 70, w = [2.], loss = 2.2873764649874577e-18\n",
      "epoch: 71, w = [2.], loss = 1.246699562468867e-18\n",
      "epoch: 72, w = [2.], loss = 6.794942062131081e-19\n",
      "epoch: 73, w = [2.], loss = 3.703477564944838e-19\n",
      "epoch: 74, w = [2.], loss = 2.0185226188154082e-19\n",
      "epoch: 75, w = [2.], loss = 1.1001648169180736e-19\n",
      "epoch: 76, w = [2.], loss = 5.996276052118673e-20\n",
      "epoch: 77, w = [2.], loss = 3.2681775950784686e-20\n",
      "epoch: 78, w = [2.], loss = 1.7812693348250185e-20\n",
      "epoch: 79, w = [2.], loss = 9.70851399631227e-21\n",
      "epoch: 80, w = [2.], loss = 5.291476093521726e-21\n",
      "epoch: 81, w = [2.], loss = 2.8840418400021275e-21\n",
      "epoch: 82, w = [2.], loss = 1.571893322803869e-21\n",
      "epoch: 83, w = [2.], loss = 8.567476131644914e-22\n",
      "epoch: 84, w = [2.], loss = 4.669564580055659e-22\n",
      "epoch: 85, w = [2.], loss = 2.54507711686596e-22\n",
      "epoch: 86, w = [2.], loss = 1.3871823693264258e-22\n",
      "epoch: 87, w = [2.], loss = 7.560484523968919e-23\n",
      "epoch: 88, w = [2.], loss = 4.120847720690175e-23\n",
      "epoch: 89, w = [2.], loss = 2.2459504159726924e-23\n",
      "epoch: 90, w = [2.], loss = 1.2241672185050329e-23\n",
      "epoch: 91, w = [2.], loss = 6.672224070144163e-24\n",
      "epoch: 92, w = [2.], loss = 3.636089230725821e-24\n",
      "epoch: 93, w = [2.], loss = 1.98187547922747e-24\n",
      "epoch: 94, w = [2.], loss = 1.0798838280564367e-24\n",
      "epoch: 95, w = [2.], loss = 5.884606400783094e-25\n",
      "epoch: 96, w = [2.], loss = 3.2083005713777145e-25\n",
      "epoch: 97, w = [2.], loss = 1.7482479186603142e-25\n",
      "epoch: 98, w = [2.], loss = 9.525783465885445e-26\n",
      "epoch: 99, w = [2.], loss = 5.18994916877772e-26\n",
      "epoch: 100, w = [2.], loss = 2.828336441484588e-26\n",
      "prediction after training: f(5) = [[10.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(20).reshape((20, 1))\n",
    "y = 2*X\n",
    "\n",
    "w = np.random.randn(1)\n",
    "\n",
    "sample = np.asarray([5])\n",
    "\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return x.dot(w).reshape((-1, 1)) \n",
    "    # need reshape to pereserve the dim\n",
    "\n",
    "# loss\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "\n",
    "# gradients\n",
    "def grad(x, y, y_pred):\n",
    "    # MSE = 1/N * (w*X - y)**2\n",
    "    # dJ/dw = 1/N * 2 * (w*X -y) * x\n",
    "    return (np.dot((2*x).T, y_pred-y)/x.shape[0]).ravel()\n",
    "\n",
    "print(f'prediction before training: f(5) = {forward(sample)}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    dw = grad(X, y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch: {epoch + 1}, w = {w}, loss = {l}')\n",
    "        \n",
    "print(f'prediction after training: f(5) = {forward(sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c311faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7d657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
