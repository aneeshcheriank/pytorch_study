{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcab7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, w = tensor([[0.4221]], requires_grad=True), b = tensor([[0.4651]], requires_grad=True), loss = 12.353740692138672\n",
      "epoch: 2, w = tensor([[0.4615]], requires_grad=True), b = tensor([[0.5330]], requires_grad=True), loss = 11.712453842163086\n",
      "epoch: 3, w = tensor([[0.4998]], requires_grad=True), b = tensor([[0.5991]], requires_grad=True), loss = 11.104458808898926\n",
      "epoch: 4, w = tensor([[0.5371]], requires_grad=True), b = tensor([[0.6635]], requires_grad=True), loss = 10.52802562713623\n",
      "epoch: 5, w = tensor([[0.5734]], requires_grad=True), b = tensor([[0.7262]], requires_grad=True), loss = 9.981515884399414\n",
      "epoch: 6, w = tensor([[0.6088]], requires_grad=True), b = tensor([[0.7873]], requires_grad=True), loss = 9.463376998901367\n",
      "epoch: 7, w = tensor([[0.6432]], requires_grad=True), b = tensor([[0.8467]], requires_grad=True), loss = 8.972136497497559\n",
      "epoch: 8, w = tensor([[0.6768]], requires_grad=True), b = tensor([[0.9046]], requires_grad=True), loss = 8.506397247314453\n",
      "epoch: 9, w = tensor([[0.7094]], requires_grad=True), b = tensor([[0.9609]], requires_grad=True), loss = 8.064835548400879\n",
      "epoch: 10, w = tensor([[0.7413]], requires_grad=True), b = tensor([[1.0158]], requires_grad=True), loss = 7.646195888519287\n",
      "epoch: 11, w = tensor([[0.7722]], requires_grad=True), b = tensor([[1.0692]], requires_grad=True), loss = 7.249289035797119\n",
      "epoch: 12, w = tensor([[0.8024]], requires_grad=True), b = tensor([[1.1212]], requires_grad=True), loss = 6.872987270355225\n",
      "epoch: 13, w = tensor([[0.8318]], requires_grad=True), b = tensor([[1.1719]], requires_grad=True), loss = 6.5162200927734375\n",
      "epoch: 14, w = tensor([[0.8604]], requires_grad=True), b = tensor([[1.2212]], requires_grad=True), loss = 6.177971839904785\n",
      "epoch: 15, w = tensor([[0.8882]], requires_grad=True), b = tensor([[1.2692]], requires_grad=True), loss = 5.857285499572754\n",
      "epoch: 16, w = tensor([[0.9153]], requires_grad=True), b = tensor([[1.3160]], requires_grad=True), loss = 5.553244590759277\n",
      "epoch: 17, w = tensor([[0.9417]], requires_grad=True), b = tensor([[1.3615]], requires_grad=True), loss = 5.264987945556641\n",
      "epoch: 18, w = tensor([[0.9674]], requires_grad=True), b = tensor([[1.4058]], requires_grad=True), loss = 4.991694927215576\n",
      "epoch: 19, w = tensor([[0.9925]], requires_grad=True), b = tensor([[1.4490]], requires_grad=True), loss = 4.732590198516846\n",
      "epoch: 20, w = tensor([[1.0169]], requires_grad=True), b = tensor([[1.4910]], requires_grad=True), loss = 4.486935615539551\n",
      "epoch: 21, w = tensor([[1.0406]], requires_grad=True), b = tensor([[1.5319]], requires_grad=True), loss = 4.25403356552124\n",
      "epoch: 22, w = tensor([[1.0637]], requires_grad=True), b = tensor([[1.5717]], requires_grad=True), loss = 4.033221244812012\n",
      "epoch: 23, w = tensor([[1.0863]], requires_grad=True), b = tensor([[1.6105]], requires_grad=True), loss = 3.8238723278045654\n",
      "epoch: 24, w = tensor([[1.1082]], requires_grad=True), b = tensor([[1.6483]], requires_grad=True), loss = 3.6253914833068848\n",
      "epoch: 25, w = tensor([[1.1295]], requires_grad=True), b = tensor([[1.6850]], requires_grad=True), loss = 3.43721342086792\n",
      "epoch: 26, w = tensor([[1.1503]], requires_grad=True), b = tensor([[1.7208]], requires_grad=True), loss = 3.258805513381958\n",
      "epoch: 27, w = tensor([[1.1706]], requires_grad=True), b = tensor([[1.7557]], requires_grad=True), loss = 3.0896573066711426\n",
      "epoch: 28, w = tensor([[1.1903]], requires_grad=True), b = tensor([[1.7896]], requires_grad=True), loss = 2.929291009902954\n",
      "epoch: 29, w = tensor([[1.2095]], requires_grad=True), b = tensor([[1.8227]], requires_grad=True), loss = 2.777249813079834\n",
      "epoch: 30, w = tensor([[1.2282]], requires_grad=True), b = tensor([[1.8548]], requires_grad=True), loss = 2.633100748062134\n",
      "epoch: 31, w = tensor([[1.2464]], requires_grad=True), b = tensor([[1.8862]], requires_grad=True), loss = 2.4964351654052734\n",
      "epoch: 32, w = tensor([[1.2641]], requires_grad=True), b = tensor([[1.9167]], requires_grad=True), loss = 2.36686372756958\n",
      "epoch: 33, w = tensor([[1.2814]], requires_grad=True), b = tensor([[1.9464]], requires_grad=True), loss = 2.244019031524658\n",
      "epoch: 34, w = tensor([[1.2982]], requires_grad=True), b = tensor([[1.9753]], requires_grad=True), loss = 2.127551317214966\n",
      "epoch: 35, w = tensor([[1.3146]], requires_grad=True), b = tensor([[2.0034]], requires_grad=True), loss = 2.017129898071289\n",
      "epoch: 36, w = tensor([[1.3306]], requires_grad=True), b = tensor([[2.0308]], requires_grad=True), loss = 1.912440538406372\n",
      "epoch: 37, w = tensor([[1.3461]], requires_grad=True), b = tensor([[2.0575]], requires_grad=True), loss = 1.813185453414917\n",
      "epoch: 38, w = tensor([[1.3612]], requires_grad=True), b = tensor([[2.0835]], requires_grad=True), loss = 1.719083547592163\n",
      "epoch: 39, w = tensor([[1.3759]], requires_grad=True), b = tensor([[2.1088]], requires_grad=True), loss = 1.629866361618042\n",
      "epoch: 40, w = tensor([[1.3903]], requires_grad=True), b = tensor([[2.1335]], requires_grad=True), loss = 1.5452806949615479\n",
      "epoch: 41, w = tensor([[1.4043]], requires_grad=True), b = tensor([[2.1574]], requires_grad=True), loss = 1.4650859832763672\n",
      "epoch: 42, w = tensor([[1.4179]], requires_grad=True), b = tensor([[2.1808]], requires_grad=True), loss = 1.3890544176101685\n",
      "epoch: 43, w = tensor([[1.4311]], requires_grad=True), b = tensor([[2.2035]], requires_grad=True), loss = 1.316969633102417\n",
      "epoch: 44, w = tensor([[1.4440]], requires_grad=True), b = tensor([[2.2257]], requires_grad=True), loss = 1.248626708984375\n",
      "epoch: 45, w = tensor([[1.4566]], requires_grad=True), b = tensor([[2.2472]], requires_grad=True), loss = 1.1838319301605225\n",
      "epoch: 46, w = tensor([[1.4688]], requires_grad=True), b = tensor([[2.2682]], requires_grad=True), loss = 1.1224006414413452\n",
      "epoch: 47, w = tensor([[1.4807]], requires_grad=True), b = tensor([[2.2886]], requires_grad=True), loss = 1.0641582012176514\n",
      "epoch: 48, w = tensor([[1.4923]], requires_grad=True), b = tensor([[2.3085]], requires_grad=True), loss = 1.008939504623413\n",
      "epoch: 49, w = tensor([[1.5037]], requires_grad=True), b = tensor([[2.3279]], requires_grad=True), loss = 0.9565868377685547\n",
      "epoch: 50, w = tensor([[1.5147]], requires_grad=True), b = tensor([[2.3468]], requires_grad=True), loss = 0.9069523811340332\n",
      "epoch: 51, w = tensor([[1.5254]], requires_grad=True), b = tensor([[2.3651]], requires_grad=True), loss = 0.8598943948745728\n",
      "epoch: 52, w = tensor([[1.5358]], requires_grad=True), b = tensor([[2.3830]], requires_grad=True), loss = 0.8152791261672974\n",
      "epoch: 53, w = tensor([[1.5460]], requires_grad=True), b = tensor([[2.4004]], requires_grad=True), loss = 0.7729799747467041\n",
      "epoch: 54, w = tensor([[1.5559]], requires_grad=True), b = tensor([[2.4174]], requires_grad=True), loss = 0.7328763604164124\n",
      "epoch: 55, w = tensor([[1.5655]], requires_grad=True), b = tensor([[2.4339]], requires_grad=True), loss = 0.6948547959327698\n",
      "epoch: 56, w = tensor([[1.5749]], requires_grad=True), b = tensor([[2.4499]], requires_grad=True), loss = 0.6588067412376404\n",
      "epoch: 57, w = tensor([[1.5841]], requires_grad=True), b = tensor([[2.4656]], requires_grad=True), loss = 0.6246301531791687\n",
      "epoch: 58, w = tensor([[1.5930]], requires_grad=True), b = tensor([[2.4808]], requires_grad=True), loss = 0.5922278165817261\n",
      "epoch: 59, w = tensor([[1.6017]], requires_grad=True), b = tensor([[2.4956]], requires_grad=True), loss = 0.5615072846412659\n",
      "epoch: 60, w = tensor([[1.6101]], requires_grad=True), b = tensor([[2.5101]], requires_grad=True), loss = 0.5323817133903503\n",
      "epoch: 61, w = tensor([[1.6184]], requires_grad=True), b = tensor([[2.5241]], requires_grad=True), loss = 0.5047680735588074\n",
      "epoch: 62, w = tensor([[1.6264]], requires_grad=True), b = tensor([[2.5378]], requires_grad=True), loss = 0.47858762741088867\n",
      "epoch: 63, w = tensor([[1.6342]], requires_grad=True), b = tensor([[2.5511]], requires_grad=True), loss = 0.453766405582428\n",
      "epoch: 64, w = tensor([[1.6418]], requires_grad=True), b = tensor([[2.5641]], requires_grad=True), loss = 0.4302333891391754\n",
      "epoch: 65, w = tensor([[1.6492]], requires_grad=True), b = tensor([[2.5767]], requires_grad=True), loss = 0.40792232751846313\n",
      "epoch: 66, w = tensor([[1.6564]], requires_grad=True), b = tensor([[2.5890]], requires_grad=True), loss = 0.3867691457271576\n",
      "epoch: 67, w = tensor([[1.6634]], requires_grad=True), b = tensor([[2.6010]], requires_grad=True), loss = 0.3667142391204834\n",
      "epoch: 68, w = tensor([[1.6703]], requires_grad=True), b = tensor([[2.6126]], requires_grad=True), loss = 0.34770017862319946\n",
      "epoch: 69, w = tensor([[1.6770]], requires_grad=True), b = tensor([[2.6240]], requires_grad=True), loss = 0.3296732008457184\n",
      "epoch: 70, w = tensor([[1.6835]], requires_grad=True), b = tensor([[2.6350]], requires_grad=True), loss = 0.31258195638656616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71, w = tensor([[1.6898]], requires_grad=True), b = tensor([[2.6458]], requires_grad=True), loss = 0.2963779866695404\n",
      "epoch: 72, w = tensor([[1.6959]], requires_grad=True), b = tensor([[2.6562]], requires_grad=True), loss = 0.28101521730422974\n",
      "epoch: 73, w = tensor([[1.7019]], requires_grad=True), b = tensor([[2.6664]], requires_grad=True), loss = 0.266449898481369\n",
      "epoch: 74, w = tensor([[1.7078]], requires_grad=True), b = tensor([[2.6764]], requires_grad=True), loss = 0.25264063477516174\n",
      "epoch: 75, w = tensor([[1.7135]], requires_grad=True), b = tensor([[2.6860]], requires_grad=True), loss = 0.23954813182353973\n",
      "epoch: 76, w = tensor([[1.7190]], requires_grad=True), b = tensor([[2.6954]], requires_grad=True), loss = 0.2271353304386139\n",
      "epoch: 77, w = tensor([[1.7244]], requires_grad=True), b = tensor([[2.7046]], requires_grad=True), loss = 0.21536676585674286\n",
      "epoch: 78, w = tensor([[1.7297]], requires_grad=True), b = tensor([[2.7135]], requires_grad=True), loss = 0.20420904457569122\n",
      "epoch: 79, w = tensor([[1.7348]], requires_grad=True), b = tensor([[2.7222]], requires_grad=True), loss = 0.19363059103488922\n",
      "epoch: 80, w = tensor([[1.7398]], requires_grad=True), b = tensor([[2.7306]], requires_grad=True), loss = 0.18360137939453125\n",
      "epoch: 81, w = tensor([[1.7447]], requires_grad=True), b = tensor([[2.7389]], requires_grad=True), loss = 0.174092635512352\n",
      "epoch: 82, w = tensor([[1.7494]], requires_grad=True), b = tensor([[2.7469]], requires_grad=True), loss = 0.16507747769355774\n",
      "epoch: 83, w = tensor([[1.7540]], requires_grad=True), b = tensor([[2.7547]], requires_grad=True), loss = 0.1565302163362503\n",
      "epoch: 84, w = tensor([[1.7585]], requires_grad=True), b = tensor([[2.7623]], requires_grad=True), loss = 0.14842674136161804\n",
      "epoch: 85, w = tensor([[1.7629]], requires_grad=True), b = tensor([[2.7697]], requires_grad=True), loss = 0.1407437026500702\n",
      "epoch: 86, w = tensor([[1.7672]], requires_grad=True), b = tensor([[2.7768]], requires_grad=True), loss = 0.13345961272716522\n",
      "epoch: 87, w = tensor([[1.7714]], requires_grad=True), b = tensor([[2.7839]], requires_grad=True), loss = 0.1265536993741989\n",
      "epoch: 88, w = tensor([[1.7754]], requires_grad=True), b = tensor([[2.7907]], requires_grad=True), loss = 0.12000604718923569\n",
      "epoch: 89, w = tensor([[1.7794]], requires_grad=True), b = tensor([[2.7973]], requires_grad=True), loss = 0.11379828304052353\n",
      "epoch: 90, w = tensor([[1.7832]], requires_grad=True), b = tensor([[2.8038]], requires_grad=True), loss = 0.10791276395320892\n",
      "epoch: 91, w = tensor([[1.7869]], requires_grad=True), b = tensor([[2.8101]], requires_grad=True), loss = 0.10233267396688461\n",
      "epoch: 92, w = tensor([[1.7906]], requires_grad=True), b = tensor([[2.8162]], requires_grad=True), loss = 0.0970422774553299\n",
      "epoch: 93, w = tensor([[1.7941]], requires_grad=True), b = tensor([[2.8221]], requires_grad=True), loss = 0.09202652424573898\n",
      "epoch: 94, w = tensor([[1.7976]], requires_grad=True), b = tensor([[2.8279]], requires_grad=True), loss = 0.08727099746465683\n",
      "epoch: 95, w = tensor([[1.8010]], requires_grad=True), b = tensor([[2.8336]], requires_grad=True), loss = 0.08276232331991196\n",
      "epoch: 96, w = tensor([[1.8043]], requires_grad=True), b = tensor([[2.8391]], requires_grad=True), loss = 0.07848768681287766\n",
      "epoch: 97, w = tensor([[1.8075]], requires_grad=True), b = tensor([[2.8445]], requires_grad=True), loss = 0.07443492114543915\n",
      "epoch: 98, w = tensor([[1.8106]], requires_grad=True), b = tensor([[2.8497]], requires_grad=True), loss = 0.07059244811534882\n",
      "epoch: 99, w = tensor([[1.8136]], requires_grad=True), b = tensor([[2.8547]], requires_grad=True), loss = 0.06694944947957993\n",
      "epoch: 100, w = tensor([[1.8166]], requires_grad=True), b = tensor([[2.8597]], requires_grad=True), loss = 0.06349547952413559\n"
     ]
    }
   ],
   "source": [
    "# loss and optimizer class in pytorch\n",
    "# pytorch model\n",
    "\n",
    "# 1. Design model(input, output size, forward pass)\n",
    "# 2. construct loss and optimizer\n",
    "# 3. Training loop\n",
    "#    - forward  pass: compute prediction\n",
    "#    - backward pass: gradients\n",
    "#    - update weights\n",
    "#    - iterate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.rand((20, 1))\n",
    "y = 2*X + 3\n",
    "\n",
    "# parameters\n",
    "w = torch.rand((1, 1), requires_grad=True)\n",
    "b = torch.rand((1, 1), requires_grad=True)\n",
    "\n",
    "# training\n",
    "lr = 0.01\n",
    "n_iter = 100\n",
    "\n",
    "loss = nn.MSELoss() # loss\n",
    "optimizer = torch.optim.SGD([w, b], lr=lr) # optimizer \n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    y = torch.matmul(x, w) + b\n",
    "    return torch.reshape(y, (-1, 1))\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    l.backward() #dl/dw    \n",
    "    \n",
    "    #  update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero graidents\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch: {epoch + 1}, w = {w}, b = {b}, loss = {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5f7d4",
   "metadata": {},
   "source": [
    "## Replace the manual model with pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b080d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, w = -0.07450525462627411, b = -0.18070200085639954, loss = 19.684349060058594\n",
      "epoch: 2, w = -0.025463689118623734, b = -0.09526287019252777, loss = 18.674667358398438\n",
      "epoch: 3, w = 0.022310730069875717, b = -0.012048475444316864, loss = 17.716787338256836\n",
      "epoch: 4, w = 0.06885091215372086, b = 0.0689990222454071, loss = 16.808048248291016\n",
      "epoch: 5, w = 0.11418892443180084, b = 0.1479359269142151, loss = 15.945930480957031\n",
      "epoch: 6, w = 0.15835601091384888, b = 0.22481711208820343, loss = 15.128039360046387\n",
      "epoch: 7, w = 0.201382577419281, b = 0.29969602823257446, loss = 14.35211181640625\n",
      "epoch: 8, w = 0.2432982623577118, b = 0.3726246654987335, loss = 13.615991592407227\n",
      "epoch: 9, w = 0.2841319441795349, b = 0.44365376234054565, loss = 12.917633056640625\n",
      "epoch: 10, w = 0.3239116966724396, b = 0.5128327012062073, loss = 12.255105972290039\n",
      "epoch: 11, w = 0.3626649081707001, b = 0.5802095532417297, loss = 11.626562118530273\n",
      "epoch: 12, w = 0.4004182517528534, b = 0.6458311080932617, loss = 11.030269622802734\n",
      "epoch: 13, w = 0.4371977150440216, b = 0.709743082523346, loss = 10.464567184448242\n",
      "epoch: 14, w = 0.47302860021591187, b = 0.7719898819923401, loss = 9.927885055541992\n",
      "epoch: 15, w = 0.5079355239868164, b = 0.8326147794723511, loss = 9.41873550415039\n",
      "epoch: 16, w = 0.5419424772262573, b = 0.8916599154472351, loss = 8.935708999633789\n",
      "epoch: 17, w = 0.5750728845596313, b = 0.9491663575172424, loss = 8.477462768554688\n",
      "epoch: 18, w = 0.6073495149612427, b = 1.005174160003662, loss = 8.042723655700684\n",
      "epoch: 19, w = 0.638794481754303, b = 1.0597221851348877, loss = 7.630287170410156\n",
      "epoch: 20, w = 0.6694294810295105, b = 1.1128485202789307, loss = 7.239012241363525\n",
      "epoch: 21, w = 0.6992754936218262, b = 1.1645900011062622, loss = 6.867807865142822\n",
      "epoch: 22, w = 0.7283530235290527, b = 1.2149826288223267, loss = 6.515649318695068\n",
      "epoch: 23, w = 0.7566820383071899, b = 1.264061450958252, loss = 6.181554317474365\n",
      "epoch: 24, w = 0.7842819690704346, b = 1.3118606805801392, loss = 5.864600658416748\n",
      "epoch: 25, w = 0.8111717700958252, b = 1.358413577079773, loss = 5.563908100128174\n",
      "epoch: 26, w = 0.8373698592185974, b = 1.4037525653839111, loss = 5.278639793395996\n",
      "epoch: 27, w = 0.8628941774368286, b = 1.4479091167449951, loss = 5.008006572723389\n",
      "epoch: 28, w = 0.8877623081207275, b = 1.490913987159729, loss = 4.75125789642334\n",
      "epoch: 29, w = 0.9119912385940552, b = 1.53279709815979, loss = 4.5076799392700195\n",
      "epoch: 30, w = 0.9355975985527039, b = 1.5735876560211182, loss = 4.276598930358887\n",
      "epoch: 31, w = 0.9585975408554077, b = 1.6133140325546265, loss = 4.057372093200684\n",
      "epoch: 32, w = 0.9810068011283875, b = 1.6520040035247803, loss = 3.849391460418701\n",
      "epoch: 33, w = 1.0028407573699951, b = 1.6896843910217285, loss = 3.6520800590515137\n",
      "epoch: 34, w = 1.0241143703460693, b = 1.7263814210891724, loss = 3.464890956878662\n",
      "epoch: 35, w = 1.0448421239852905, b = 1.7621207237243652, loss = 3.2873053550720215\n",
      "epoch: 36, w = 1.0650382041931152, b = 1.7969272136688232, loss = 3.1188302040100098\n",
      "epoch: 37, w = 1.0847164392471313, b = 1.8308250904083252, loss = 2.9589970111846924\n",
      "epoch: 38, w = 1.103890299797058, b = 1.8638379573822021, loss = 2.807363986968994\n",
      "epoch: 39, w = 1.1225727796554565, b = 1.8959888219833374, loss = 2.663508892059326\n",
      "epoch: 40, w = 1.1407767534255981, b = 1.9273000955581665, loss = 2.527034282684326\n",
      "epoch: 41, w = 1.1585146188735962, b = 1.9577937126159668, loss = 2.3975605964660645\n",
      "epoch: 42, w = 1.1757984161376953, b = 1.9874907732009888, loss = 2.274728775024414\n",
      "epoch: 43, w = 1.1926400661468506, b = 2.0164120197296143, loss = 2.1581978797912598\n",
      "epoch: 44, w = 1.2090508937835693, b = 2.0445775985717773, loss = 2.047645330429077\n",
      "epoch: 45, w = 1.2250422239303589, b = 2.072007417678833, loss = 1.9427642822265625\n",
      "epoch: 46, w = 1.2406249046325684, b = 2.0987203121185303, loss = 1.8432626724243164\n",
      "epoch: 47, w = 1.2558095455169678, b = 2.124735116958618, loss = 1.7488653659820557\n",
      "epoch: 48, w = 1.2706063985824585, b = 2.1500697135925293, loss = 1.6593105792999268\n",
      "epoch: 49, w = 1.2850255966186523, b = 2.1747419834136963, loss = 1.5743498802185059\n",
      "epoch: 50, w = 1.2990769147872925, b = 2.1987690925598145, loss = 1.493747591972351\n",
      "epoch: 51, w = 1.3127700090408325, b = 2.22216796875, loss = 1.417279839515686\n",
      "epoch: 52, w = 1.3261140584945679, b = 2.2449545860290527, loss = 1.3447343111038208\n",
      "epoch: 53, w = 1.339118242263794, b = 2.2671451568603516, loss = 1.2759106159210205\n",
      "epoch: 54, w = 1.351791262626648, b = 2.288755178451538, loss = 1.210617184638977\n",
      "epoch: 55, w = 1.3641417026519775, b = 2.3097996711730957, loss = 1.1486728191375732\n",
      "epoch: 56, w = 1.3761780261993408, b = 2.3302934169769287, loss = 1.0899059772491455\n",
      "epoch: 57, w = 1.3879083395004272, b = 2.350250482559204, loss = 1.0341534614562988\n",
      "epoch: 58, w = 1.3993406295776367, b = 2.369685173034668, loss = 0.9812610745429993\n",
      "epoch: 59, w = 1.41048264503479, b = 2.38861083984375, loss = 0.9310812950134277\n",
      "epoch: 60, w = 1.421341896057129, b = 2.407040596008301, loss = 0.883475661277771\n",
      "epoch: 61, w = 1.431925654411316, b = 2.424987554550171, loss = 0.838312029838562\n",
      "epoch: 62, w = 1.4422410726547241, b = 2.4424643516540527, loss = 0.7954648733139038\n",
      "epoch: 63, w = 1.452295184135437, b = 2.4594831466674805, loss = 0.7548153400421143\n",
      "epoch: 64, w = 1.462094783782959, b = 2.47605562210083, loss = 0.7162507176399231\n",
      "epoch: 65, w = 1.4716464281082153, b = 2.4921936988830566, loss = 0.6796643137931824\n",
      "epoch: 66, w = 1.4809565544128418, b = 2.507908344268799, loss = 0.6449541449546814\n",
      "epoch: 67, w = 1.4900314807891846, b = 2.5232107639312744, loss = 0.6120246648788452\n",
      "epoch: 68, w = 1.4988772869110107, b = 2.538111686706543, loss = 0.5807837843894958\n",
      "epoch: 69, w = 1.5074998140335083, b = 2.552621603012085, loss = 0.5511453747749329\n",
      "epoch: 70, w = 1.5159050226211548, b = 2.5667505264282227, loss = 0.5230268239974976\n",
      "epoch: 71, w = 1.5240983963012695, b = 2.5805084705352783, loss = 0.4963505268096924\n",
      "epoch: 72, w = 1.5320855379104614, b = 2.593904972076416, loss = 0.47104233503341675\n",
      "epoch: 73, w = 1.5398716926574707, b = 2.6069495677948, loss = 0.44703206419944763\n",
      "epoch: 74, w = 1.5474622249603271, b = 2.6196513175964355, loss = 0.4242532253265381\n",
      "epoch: 75, w = 1.554862141609192, b = 2.632019281387329, loss = 0.40264254808425903\n",
      "epoch: 76, w = 1.5620763301849365, b = 2.644062042236328, loss = 0.38213977217674255\n",
      "epoch: 77, w = 1.5691096782684326, b = 2.655787944793701, loss = 0.3626886010169983\n",
      "epoch: 78, w = 1.5759668350219727, b = 2.667205333709717, loss = 0.3442348539829254\n",
      "epoch: 79, w = 1.5826523303985596, b = 2.6783223152160645, loss = 0.3267274498939514\n",
      "epoch: 80, w = 1.5891706943511963, b = 2.6891465187072754, loss = 0.3101176619529724\n",
      "epoch: 81, w = 1.5955262184143066, b = 2.69968581199646, loss = 0.29435965418815613\n",
      "epoch: 82, w = 1.601723074913025, b = 2.709947347640991, loss = 0.2794095277786255\n",
      "epoch: 83, w = 1.6077654361724854, b = 2.7199385166168213, loss = 0.26522597670555115\n",
      "epoch: 84, w = 1.6136573553085327, b = 2.729666233062744, loss = 0.25176969170570374\n",
      "epoch: 85, w = 1.6194026470184326, b = 2.7391374111175537, loss = 0.23900321125984192\n",
      "epoch: 86, w = 1.6250052452087402, b = 2.748358726501465, loss = 0.22689136862754822\n",
      "epoch: 87, w = 1.630468726158142, b = 2.7573366165161133, loss = 0.21540036797523499\n",
      "epoch: 88, w = 1.6357966661453247, b = 2.7660775184631348, loss = 0.20449844002723694\n",
      "epoch: 89, w = 1.6409926414489746, b = 2.774587631225586, loss = 0.19415536522865295\n",
      "epoch: 90, w = 1.6460601091384888, b = 2.7828729152679443, loss = 0.1843423843383789\n",
      "epoch: 91, w = 1.6510024070739746, b = 2.7909390926361084, loss = 0.175032377243042\n",
      "epoch: 92, w = 1.6558226346969604, b = 2.7987918853759766, loss = 0.16619960963726044\n",
      "epoch: 93, w = 1.6605241298675537, b = 2.8064370155334473, loss = 0.1578197181224823\n",
      "epoch: 94, w = 1.6651098728179932, b = 2.8138797283172607, loss = 0.14986908435821533\n",
      "epoch: 95, w = 1.6695828437805176, b = 2.8211252689361572, loss = 0.14232592284679413\n",
      "epoch: 96, w = 1.6739460229873657, b = 2.828178882598877, loss = 0.13516941666603088\n",
      "epoch: 97, w = 1.6782021522521973, b = 2.835045576095581, loss = 0.12837955355644226\n",
      "epoch: 98, w = 1.6823540925979614, b = 2.8417301177978516, loss = 0.121937595307827\n",
      "epoch: 99, w = 1.6864045858383179, b = 2.8482372760772705, loss = 0.11582567542791367\n",
      "epoch: 100, w = 1.6903561353683472, b = 2.85457181930542, loss = 0.11002699285745621\n"
     ]
    }
   ],
   "source": [
    "# loss and optimizer class in pytorch\n",
    "# pytorch model\n",
    "\n",
    "# 1. Design model(input, output size, forward pass)\n",
    "# 2. construct loss and optimizer\n",
    "# 3. Training loop\n",
    "#    - forward  pass: compute prediction\n",
    "#    - backward pass: gradients\n",
    "#    - update weights\n",
    "#    - iterate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.rand((20, 1))\n",
    "y = 2*X + 3\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "model = nn.Linear(n_features, 1, bias=True)\n",
    "\n",
    "lr = 0.01\n",
    "loss = nn.MSELoss() # loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # optimizer \n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    l.backward() #dl/dw    \n",
    "    \n",
    "    #  update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero graidents\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(f'epoch: {epoch + 1}, w = {w.item()}, b = {b.item()}, loss = {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c79c90",
   "metadata": {},
   "source": [
    "## Custom Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28fd9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, w = -0.6650240421295166, b = -0.622509241104126, loss = 23.541961669921875\n",
      "epoch: 2, w = -0.6237175464630127, b = -0.5289098620414734, loss = 22.457382202148438\n",
      "epoch: 3, w = -0.5833484530448914, b = -0.43751025199890137, loss = 21.42290496826172\n",
      "epoch: 4, w = -0.5438949465751648, b = -0.34825897216796875, loss = 20.43621253967285\n",
      "epoch: 5, w = -0.5053356289863586, b = -0.26110583543777466, loss = 19.495105743408203\n",
      "epoch: 6, w = -0.4676496684551239, b = -0.17600175738334656, loss = 18.597469329833984\n",
      "epoch: 7, w = -0.4308166801929474, b = -0.09289883822202682, loss = 17.74129867553711\n",
      "epoch: 8, w = -0.3948167562484741, b = -0.011750280857086182, loss = 16.92467498779297\n",
      "epoch: 9, w = -0.3596304655075073, b = 0.0674896240234375, loss = 16.14577865600586\n",
      "epoch: 10, w = -0.32523882389068604, b = 0.1448654979467392, loss = 15.402856826782227\n",
      "epoch: 11, w = -0.2916232943534851, b = 0.2204209268093109, loss = 14.694253921508789\n",
      "epoch: 12, w = -0.2587657570838928, b = 0.29419848322868347, loss = 14.018381118774414\n",
      "epoch: 13, w = -0.22664856910705566, b = 0.3662397265434265, loss = 13.373727798461914\n",
      "epoch: 14, w = -0.19525444507598877, b = 0.43658527731895447, loss = 12.758852005004883\n",
      "epoch: 15, w = -0.1645665168762207, b = 0.505274772644043, loss = 12.172375679016113\n",
      "epoch: 16, w = -0.13456830382347107, b = 0.5723469257354736, loss = 11.61298942565918\n",
      "epoch: 17, w = -0.1052437350153923, b = 0.6378396153450012, loss = 11.079439163208008\n",
      "epoch: 18, w = -0.0765770971775055, b = 0.7017897367477417, loss = 10.57053279876709\n",
      "epoch: 19, w = -0.048553042113780975, b = 0.7642333507537842, loss = 10.085132598876953\n",
      "epoch: 20, w = -0.021156594157218933, b = 0.8252056837081909, loss = 9.622148513793945\n",
      "epoch: 21, w = 0.005626879632472992, b = 0.8847411870956421, loss = 9.180549621582031\n",
      "epoch: 22, w = 0.03181167319417, b = 0.9428734183311462, loss = 8.759346961975098\n",
      "epoch: 23, w = 0.05741174519062042, b = 0.9996352195739746, loss = 8.357595443725586\n",
      "epoch: 24, w = 0.08244072645902634, b = 1.0550585985183716, loss = 7.974398612976074\n",
      "epoch: 25, w = 0.10691192746162415, b = 1.1091748476028442, loss = 7.6088995933532715\n",
      "epoch: 26, w = 0.13083834946155548, b = 1.1620146036148071, loss = 7.260279178619385\n",
      "epoch: 27, w = 0.1542326807975769, b = 1.213607668876648, loss = 6.92775821685791\n",
      "epoch: 28, w = 0.1771073341369629, b = 1.2639832496643066, loss = 6.610591888427734\n",
      "epoch: 29, w = 0.19947442412376404, b = 1.3131698369979858, loss = 6.308072566986084\n",
      "epoch: 30, w = 0.22134576737880707, b = 1.3611950874328613, loss = 6.019522666931152\n",
      "epoch: 31, w = 0.2427329272031784, b = 1.4080862998962402, loss = 5.744296550750732\n",
      "epoch: 32, w = 0.2636471688747406, b = 1.4538699388504028, loss = 5.4817795753479\n",
      "epoch: 33, w = 0.2840995192527771, b = 1.4985719919204712, loss = 5.231383800506592\n",
      "epoch: 34, w = 0.30410075187683105, b = 1.54221773147583, loss = 4.992549419403076\n",
      "epoch: 35, w = 0.32366135716438293, b = 1.5848318338394165, loss = 4.764741897583008\n",
      "epoch: 36, w = 0.3427916169166565, b = 1.6264383792877197, loss = 4.547451019287109\n",
      "epoch: 37, w = 0.361501544713974, b = 1.6670609712600708, loss = 4.340192794799805\n",
      "epoch: 38, w = 0.3798009157180786, b = 1.706722617149353, loss = 4.142502784729004\n",
      "epoch: 39, w = 0.3976992964744568, b = 1.7454458475112915, loss = 3.953939914703369\n",
      "epoch: 40, w = 0.41520604491233826, b = 1.7832525968551636, loss = 3.774080753326416\n",
      "epoch: 41, w = 0.43233025074005127, b = 1.8201642036437988, loss = 3.6025238037109375\n",
      "epoch: 42, w = 0.44908085465431213, b = 1.8562016487121582, loss = 3.4388866424560547\n",
      "epoch: 43, w = 0.46546652913093567, b = 1.8913854360580444, loss = 3.2828025817871094\n",
      "epoch: 44, w = 0.48149576783180237, b = 1.925735592842102, loss = 3.1339218616485596\n",
      "epoch: 45, w = 0.4971768856048584, b = 1.9592715501785278, loss = 2.991912603378296\n",
      "epoch: 46, w = 0.5125179290771484, b = 1.9920122623443604, loss = 2.856457233428955\n",
      "epoch: 47, w = 0.52752685546875, b = 2.0239763259887695, loss = 2.72725248336792\n",
      "epoch: 48, w = 0.5422114133834839, b = 2.0551822185516357, loss = 2.604010820388794\n",
      "epoch: 49, w = 0.5565791130065918, b = 2.0856473445892334, loss = 2.486455202102661\n",
      "epoch: 50, w = 0.5706373453140259, b = 2.115389108657837, loss = 2.3743233680725098\n",
      "epoch: 51, w = 0.584393322467804, b = 2.1444244384765625, loss = 2.2673659324645996\n",
      "epoch: 52, w = 0.5978540182113647, b = 2.1727700233459473, loss = 2.165342092514038\n",
      "epoch: 53, w = 0.6110263466835022, b = 2.200441837310791, loss = 2.0680251121520996\n",
      "epoch: 54, w = 0.6239169836044312, b = 2.2274556159973145, loss = 1.9751970767974854\n",
      "epoch: 55, w = 0.6365325450897217, b = 2.253826856613159, loss = 1.8866504430770874\n",
      "epoch: 56, w = 0.64887934923172, b = 2.2795705795288086, loss = 1.8021879196166992\n",
      "epoch: 57, w = 0.6609636545181274, b = 2.304701566696167, loss = 1.7216209173202515\n",
      "epoch: 58, w = 0.672791600227356, b = 2.3292338848114014, loss = 1.6447683572769165\n",
      "epoch: 59, w = 0.6843691468238831, b = 2.353181838989258, loss = 1.5714596509933472\n",
      "epoch: 60, w = 0.695702075958252, b = 2.376558780670166, loss = 1.501530647277832\n",
      "epoch: 61, w = 0.7067960500717163, b = 2.3993782997131348, loss = 1.4348260164260864\n",
      "epoch: 62, w = 0.717656672000885, b = 2.4216535091400146, loss = 1.3711957931518555\n",
      "epoch: 63, w = 0.7282893657684326, b = 2.443396806716919, loss = 1.3104981184005737\n",
      "epoch: 64, w = 0.7386993765830994, b = 2.464621067047119, loss = 1.2525981664657593\n",
      "epoch: 65, w = 0.7488918900489807, b = 2.4853382110595703, loss = 1.1973659992218018\n",
      "epoch: 66, w = 0.7588719725608826, b = 2.5055601596832275, loss = 1.1446788311004639\n",
      "epoch: 67, w = 0.7686445713043213, b = 2.5252983570098877, loss = 1.0944185256958008\n",
      "epoch: 68, w = 0.7782144546508789, b = 2.5445642471313477, loss = 1.0464738607406616\n",
      "epoch: 69, w = 0.7875863313674927, b = 2.563368797302246, loss = 1.0007373094558716\n",
      "epoch: 70, w = 0.7967648506164551, b = 2.5817229747772217, loss = 0.9571069478988647\n",
      "epoch: 71, w = 0.8057544231414795, b = 2.599637269973755, loss = 0.9154852628707886\n",
      "epoch: 72, w = 0.8145594596862793, b = 2.617121934890747, loss = 0.8757797479629517\n",
      "epoch: 73, w = 0.8231842517852783, b = 2.6341869831085205, loss = 0.8379015922546387\n",
      "epoch: 74, w = 0.8316329717636108, b = 2.6508421897888184, loss = 0.8017668724060059\n",
      "epoch: 75, w = 0.8399097323417664, b = 2.667097330093384, loss = 0.7672950029373169\n",
      "epoch: 76, w = 0.8480184674263, b = 2.6829617023468018, loss = 0.7344086766242981\n",
      "epoch: 77, w = 0.8559631109237671, b = 2.698444366455078, loss = 0.7030349969863892\n",
      "epoch: 78, w = 0.8637474775314331, b = 2.7135543823242188, loss = 0.6731040477752686\n",
      "epoch: 79, w = 0.8713752031326294, b = 2.7283003330230713, loss = 0.6445491313934326\n",
      "epoch: 80, w = 0.878849983215332, b = 2.7426910400390625, loss = 0.6173068881034851\n",
      "epoch: 81, w = 0.8861753344535828, b = 2.756734609603882, loss = 0.5913161039352417\n",
      "epoch: 82, w = 0.8933547139167786, b = 2.7704391479492188, loss = 0.566519558429718\n",
      "epoch: 83, w = 0.9003915190696716, b = 2.7838125228881836, loss = 0.5428619980812073\n",
      "epoch: 84, w = 0.9072890281677246, b = 2.7968626022338867, loss = 0.520290732383728\n",
      "epoch: 85, w = 0.9140504598617554, b = 2.8095970153808594, loss = 0.49875563383102417\n",
      "epoch: 86, w = 0.920678973197937, b = 2.8220229148864746, loss = 0.4782087802886963\n",
      "epoch: 87, w = 0.9271776676177979, b = 2.8341476917266846, loss = 0.45860475301742554\n",
      "epoch: 88, w = 0.9335494637489319, b = 2.8459784984588623, loss = 0.43989986181259155\n",
      "epoch: 89, w = 0.9397973418235779, b = 2.8575220108032227, loss = 0.42205238342285156\n",
      "epoch: 90, w = 0.9459242224693298, b = 2.8687851428985596, loss = 0.40502309799194336\n",
      "epoch: 91, w = 0.9519328474998474, b = 2.879774332046509, loss = 0.3887738585472107\n",
      "epoch: 92, w = 0.9578258991241455, b = 2.890496253967285, loss = 0.37326890230178833\n",
      "epoch: 93, w = 0.9636061191558838, b = 2.900956869125366, loss = 0.3584734797477722\n",
      "epoch: 94, w = 0.9692760705947876, b = 2.9111623764038086, loss = 0.3443552851676941\n",
      "epoch: 95, w = 0.9748383164405823, b = 2.92111873626709, loss = 0.3308827579021454\n",
      "epoch: 96, w = 0.9802953600883484, b = 2.9308319091796875, loss = 0.3180263042449951\n",
      "epoch: 97, w = 0.985649585723877, b = 2.940307378768921, loss = 0.30575722455978394\n",
      "epoch: 98, w = 0.990903377532959, b = 2.9495508670806885, loss = 0.2940487265586853\n",
      "epoch: 99, w = 0.9960590600967407, b = 2.9585678577423096, loss = 0.2828746438026428\n",
      "epoch: 100, w = 1.0011188983917236, b = 2.9673635959625244, loss = 0.27221035957336426\n"
     ]
    }
   ],
   "source": [
    "# loss and optimizer class in pytorch\n",
    "# pytorch model\n",
    "\n",
    "# 1. Design model(input, output size, forward pass)\n",
    "# 2. construct loss and optimizer\n",
    "# 3. Training loop\n",
    "#    - forward  pass: compute prediction\n",
    "#    - backward pass: gradients\n",
    "#    - update weights\n",
    "#    - iterate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.rand((20, 1))\n",
    "y = 2*X + 3\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# model = nn.Linear(n_features, 1, bias=True)\n",
    "# define the model class\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "# create the class object\n",
    "model = LinearRegression(n_features, 1)\n",
    "\n",
    "lr = 0.01\n",
    "loss = nn.MSELoss() # loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # optimizer \n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    l.backward() #dl/dw    \n",
    "    \n",
    "    #  update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero graidents\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(f'epoch: {epoch + 1}, w = {w.item()}, b = {b.item()}, loss = {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445ccc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
