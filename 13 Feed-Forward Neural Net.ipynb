{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# DataLoader, Trasfornations\n",
    "# Multilayer Neural Net, activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop\n",
    "# Model evaluation\n",
    "# GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db02705948d4a989f7303c42b0c4c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75ca9c0ebcb4844ac9b37237e9b8a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f963140774c46fb91f39906467f6e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ed238ea4754520945851b651a83143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "EPOCHS = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data', train=True, transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data', train=False, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# to load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset, batch_size = batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset, batch_size = batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# check all are working good\n",
    "example = iter(train_loader)\n",
    "samples, labels = example.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 1/2, step 5/600, loss = 2.1428\n",
      "eopch: 1/2, step 10/600, loss = 1.9162\n",
      "eopch: 1/2, step 15/600, loss = 1.6392\n",
      "eopch: 1/2, step 20/600, loss = 1.4517\n",
      "eopch: 1/2, step 25/600, loss = 1.2635\n",
      "eopch: 1/2, step 30/600, loss = 0.9911\n",
      "eopch: 1/2, step 35/600, loss = 0.9066\n",
      "eopch: 1/2, step 40/600, loss = 0.7928\n",
      "eopch: 1/2, step 45/600, loss = 0.6807\n",
      "eopch: 1/2, step 50/600, loss = 0.8008\n",
      "eopch: 1/2, step 55/600, loss = 0.6008\n",
      "eopch: 1/2, step 60/600, loss = 0.6038\n",
      "eopch: 1/2, step 65/600, loss = 0.7541\n",
      "eopch: 1/2, step 70/600, loss = 0.5301\n",
      "eopch: 1/2, step 75/600, loss = 0.5153\n",
      "eopch: 1/2, step 80/600, loss = 0.5359\n",
      "eopch: 1/2, step 85/600, loss = 0.5114\n",
      "eopch: 1/2, step 90/600, loss = 0.4600\n",
      "eopch: 1/2, step 95/600, loss = 0.5454\n",
      "eopch: 1/2, step 100/600, loss = 0.4389\n",
      "eopch: 1/2, step 105/600, loss = 0.3491\n",
      "eopch: 1/2, step 110/600, loss = 0.5114\n",
      "eopch: 1/2, step 115/600, loss = 0.6581\n",
      "eopch: 1/2, step 120/600, loss = 0.3567\n",
      "eopch: 1/2, step 125/600, loss = 0.3085\n",
      "eopch: 1/2, step 130/600, loss = 0.2751\n",
      "eopch: 1/2, step 135/600, loss = 0.3300\n",
      "eopch: 1/2, step 140/600, loss = 0.3420\n",
      "eopch: 1/2, step 145/600, loss = 0.2564\n",
      "eopch: 1/2, step 150/600, loss = 0.3358\n",
      "eopch: 1/2, step 155/600, loss = 0.4004\n",
      "eopch: 1/2, step 160/600, loss = 0.5069\n",
      "eopch: 1/2, step 165/600, loss = 0.2673\n",
      "eopch: 1/2, step 170/600, loss = 0.2913\n",
      "eopch: 1/2, step 175/600, loss = 0.4614\n",
      "eopch: 1/2, step 180/600, loss = 0.3980\n",
      "eopch: 1/2, step 185/600, loss = 0.3580\n",
      "eopch: 1/2, step 190/600, loss = 0.3344\n",
      "eopch: 1/2, step 195/600, loss = 0.2546\n",
      "eopch: 1/2, step 200/600, loss = 0.3072\n",
      "eopch: 1/2, step 205/600, loss = 0.3560\n",
      "eopch: 1/2, step 210/600, loss = 0.3742\n",
      "eopch: 1/2, step 215/600, loss = 0.3624\n",
      "eopch: 1/2, step 220/600, loss = 0.3654\n",
      "eopch: 1/2, step 225/600, loss = 0.4091\n",
      "eopch: 1/2, step 230/600, loss = 0.2820\n",
      "eopch: 1/2, step 235/600, loss = 0.4464\n",
      "eopch: 1/2, step 240/600, loss = 0.4605\n",
      "eopch: 1/2, step 245/600, loss = 0.3739\n",
      "eopch: 1/2, step 250/600, loss = 0.2184\n",
      "eopch: 1/2, step 255/600, loss = 0.3014\n",
      "eopch: 1/2, step 260/600, loss = 0.3082\n",
      "eopch: 1/2, step 265/600, loss = 0.3769\n",
      "eopch: 1/2, step 270/600, loss = 0.3343\n",
      "eopch: 1/2, step 275/600, loss = 0.3187\n",
      "eopch: 1/2, step 280/600, loss = 0.2656\n",
      "eopch: 1/2, step 285/600, loss = 0.2607\n",
      "eopch: 1/2, step 290/600, loss = 0.3226\n",
      "eopch: 1/2, step 295/600, loss = 0.2191\n",
      "eopch: 1/2, step 300/600, loss = 0.3570\n",
      "eopch: 1/2, step 305/600, loss = 0.4599\n",
      "eopch: 1/2, step 310/600, loss = 0.2314\n",
      "eopch: 1/2, step 315/600, loss = 0.1400\n",
      "eopch: 1/2, step 320/600, loss = 0.3270\n",
      "eopch: 1/2, step 325/600, loss = 0.3377\n",
      "eopch: 1/2, step 330/600, loss = 0.3763\n",
      "eopch: 1/2, step 335/600, loss = 0.3802\n",
      "eopch: 1/2, step 340/600, loss = 0.3432\n",
      "eopch: 1/2, step 345/600, loss = 0.3675\n",
      "eopch: 1/2, step 350/600, loss = 0.3492\n",
      "eopch: 1/2, step 355/600, loss = 0.2336\n",
      "eopch: 1/2, step 360/600, loss = 0.2387\n",
      "eopch: 1/2, step 365/600, loss = 0.2381\n",
      "eopch: 1/2, step 370/600, loss = 0.2258\n",
      "eopch: 1/2, step 375/600, loss = 0.4146\n",
      "eopch: 1/2, step 380/600, loss = 0.2626\n",
      "eopch: 1/2, step 385/600, loss = 0.2672\n",
      "eopch: 1/2, step 390/600, loss = 0.3637\n",
      "eopch: 1/2, step 395/600, loss = 0.3882\n",
      "eopch: 1/2, step 400/600, loss = 0.2960\n",
      "eopch: 1/2, step 405/600, loss = 0.3258\n",
      "eopch: 1/2, step 410/600, loss = 0.1918\n",
      "eopch: 1/2, step 415/600, loss = 0.3520\n",
      "eopch: 1/2, step 420/600, loss = 0.2400\n",
      "eopch: 1/2, step 425/600, loss = 0.2198\n",
      "eopch: 1/2, step 430/600, loss = 0.4244\n",
      "eopch: 1/2, step 435/600, loss = 0.1845\n",
      "eopch: 1/2, step 440/600, loss = 0.3270\n",
      "eopch: 1/2, step 445/600, loss = 0.1827\n",
      "eopch: 1/2, step 450/600, loss = 0.3021\n",
      "eopch: 1/2, step 455/600, loss = 0.2224\n",
      "eopch: 1/2, step 460/600, loss = 0.3905\n",
      "eopch: 1/2, step 465/600, loss = 0.1823\n",
      "eopch: 1/2, step 470/600, loss = 0.4074\n",
      "eopch: 1/2, step 475/600, loss = 0.2264\n",
      "eopch: 1/2, step 480/600, loss = 0.2960\n",
      "eopch: 1/2, step 485/600, loss = 0.2862\n",
      "eopch: 1/2, step 490/600, loss = 0.3280\n",
      "eopch: 1/2, step 495/600, loss = 0.2479\n",
      "eopch: 1/2, step 500/600, loss = 0.1727\n",
      "eopch: 1/2, step 505/600, loss = 0.3155\n",
      "eopch: 1/2, step 510/600, loss = 0.2107\n",
      "eopch: 1/2, step 515/600, loss = 0.3218\n",
      "eopch: 1/2, step 520/600, loss = 0.3783\n",
      "eopch: 1/2, step 525/600, loss = 0.3803\n",
      "eopch: 1/2, step 530/600, loss = 0.2403\n",
      "eopch: 1/2, step 535/600, loss = 0.1263\n",
      "eopch: 1/2, step 540/600, loss = 0.2488\n",
      "eopch: 1/2, step 545/600, loss = 0.2760\n",
      "eopch: 1/2, step 550/600, loss = 0.2694\n",
      "eopch: 1/2, step 555/600, loss = 0.2303\n",
      "eopch: 1/2, step 560/600, loss = 0.1960\n",
      "eopch: 1/2, step 565/600, loss = 0.1739\n",
      "eopch: 1/2, step 570/600, loss = 0.5073\n",
      "eopch: 1/2, step 575/600, loss = 0.3736\n",
      "eopch: 1/2, step 580/600, loss = 0.2559\n",
      "eopch: 1/2, step 585/600, loss = 0.1954\n",
      "eopch: 1/2, step 590/600, loss = 0.2062\n",
      "eopch: 1/2, step 595/600, loss = 0.2282\n",
      "eopch: 1/2, step 600/600, loss = 0.2280\n",
      "eopch: 2/2, step 5/600, loss = 0.2093\n",
      "eopch: 2/2, step 10/600, loss = 0.1356\n",
      "eopch: 2/2, step 15/600, loss = 0.1002\n",
      "eopch: 2/2, step 20/600, loss = 0.3119\n",
      "eopch: 2/2, step 25/600, loss = 0.2526\n",
      "eopch: 2/2, step 30/600, loss = 0.1721\n",
      "eopch: 2/2, step 35/600, loss = 0.1637\n",
      "eopch: 2/2, step 40/600, loss = 0.2081\n",
      "eopch: 2/2, step 45/600, loss = 0.1843\n",
      "eopch: 2/2, step 50/600, loss = 0.2228\n",
      "eopch: 2/2, step 55/600, loss = 0.1581\n",
      "eopch: 2/2, step 60/600, loss = 0.1593\n",
      "eopch: 2/2, step 65/600, loss = 0.0741\n",
      "eopch: 2/2, step 70/600, loss = 0.1397\n",
      "eopch: 2/2, step 75/600, loss = 0.2486\n",
      "eopch: 2/2, step 80/600, loss = 0.1799\n",
      "eopch: 2/2, step 85/600, loss = 0.2494\n",
      "eopch: 2/2, step 90/600, loss = 0.2588\n",
      "eopch: 2/2, step 95/600, loss = 0.2593\n",
      "eopch: 2/2, step 100/600, loss = 0.1275\n",
      "eopch: 2/2, step 105/600, loss = 0.3165\n",
      "eopch: 2/2, step 110/600, loss = 0.1941\n",
      "eopch: 2/2, step 115/600, loss = 0.2241\n",
      "eopch: 2/2, step 120/600, loss = 0.1707\n",
      "eopch: 2/2, step 125/600, loss = 0.3122\n",
      "eopch: 2/2, step 130/600, loss = 0.1853\n",
      "eopch: 2/2, step 135/600, loss = 0.1629\n",
      "eopch: 2/2, step 140/600, loss = 0.3744\n",
      "eopch: 2/2, step 145/600, loss = 0.1856\n",
      "eopch: 2/2, step 150/600, loss = 0.2028\n",
      "eopch: 2/2, step 155/600, loss = 0.2452\n",
      "eopch: 2/2, step 160/600, loss = 0.2391\n",
      "eopch: 2/2, step 165/600, loss = 0.1539\n",
      "eopch: 2/2, step 170/600, loss = 0.2385\n",
      "eopch: 2/2, step 175/600, loss = 0.1842\n",
      "eopch: 2/2, step 180/600, loss = 0.1327\n",
      "eopch: 2/2, step 185/600, loss = 0.2447\n",
      "eopch: 2/2, step 190/600, loss = 0.2383\n",
      "eopch: 2/2, step 195/600, loss = 0.2131\n",
      "eopch: 2/2, step 200/600, loss = 0.3730\n",
      "eopch: 2/2, step 205/600, loss = 0.1722\n",
      "eopch: 2/2, step 210/600, loss = 0.1586\n",
      "eopch: 2/2, step 215/600, loss = 0.2307\n",
      "eopch: 2/2, step 220/600, loss = 0.1293\n",
      "eopch: 2/2, step 225/600, loss = 0.1171\n",
      "eopch: 2/2, step 230/600, loss = 0.1913\n",
      "eopch: 2/2, step 235/600, loss = 0.2352\n",
      "eopch: 2/2, step 240/600, loss = 0.3613\n",
      "eopch: 2/2, step 245/600, loss = 0.2963\n",
      "eopch: 2/2, step 250/600, loss = 0.2172\n",
      "eopch: 2/2, step 255/600, loss = 0.2669\n",
      "eopch: 2/2, step 260/600, loss = 0.0925\n",
      "eopch: 2/2, step 265/600, loss = 0.1039\n",
      "eopch: 2/2, step 270/600, loss = 0.2348\n",
      "eopch: 2/2, step 275/600, loss = 0.2239\n",
      "eopch: 2/2, step 280/600, loss = 0.2584\n",
      "eopch: 2/2, step 285/600, loss = 0.1974\n",
      "eopch: 2/2, step 290/600, loss = 0.2197\n",
      "eopch: 2/2, step 295/600, loss = 0.1821\n",
      "eopch: 2/2, step 300/600, loss = 0.1537\n",
      "eopch: 2/2, step 305/600, loss = 0.2226\n",
      "eopch: 2/2, step 310/600, loss = 0.1356\n",
      "eopch: 2/2, step 315/600, loss = 0.3805\n",
      "eopch: 2/2, step 320/600, loss = 0.1563\n",
      "eopch: 2/2, step 325/600, loss = 0.1749\n",
      "eopch: 2/2, step 330/600, loss = 0.2483\n",
      "eopch: 2/2, step 335/600, loss = 0.2259\n",
      "eopch: 2/2, step 340/600, loss = 0.1980\n",
      "eopch: 2/2, step 345/600, loss = 0.1821\n",
      "eopch: 2/2, step 350/600, loss = 0.1871\n",
      "eopch: 2/2, step 355/600, loss = 0.3548\n",
      "eopch: 2/2, step 360/600, loss = 0.2796\n",
      "eopch: 2/2, step 365/600, loss = 0.2347\n",
      "eopch: 2/2, step 370/600, loss = 0.1518\n",
      "eopch: 2/2, step 375/600, loss = 0.1187\n",
      "eopch: 2/2, step 380/600, loss = 0.3967\n",
      "eopch: 2/2, step 385/600, loss = 0.1901\n",
      "eopch: 2/2, step 390/600, loss = 0.2122\n",
      "eopch: 2/2, step 395/600, loss = 0.3141\n",
      "eopch: 2/2, step 400/600, loss = 0.1834\n",
      "eopch: 2/2, step 405/600, loss = 0.2143\n",
      "eopch: 2/2, step 410/600, loss = 0.1108\n",
      "eopch: 2/2, step 415/600, loss = 0.0968\n",
      "eopch: 2/2, step 420/600, loss = 0.1202\n",
      "eopch: 2/2, step 425/600, loss = 0.1293\n",
      "eopch: 2/2, step 430/600, loss = 0.2198\n",
      "eopch: 2/2, step 435/600, loss = 0.2115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 2/2, step 440/600, loss = 0.2123\n",
      "eopch: 2/2, step 445/600, loss = 0.1617\n",
      "eopch: 2/2, step 450/600, loss = 0.3064\n",
      "eopch: 2/2, step 455/600, loss = 0.1662\n",
      "eopch: 2/2, step 460/600, loss = 0.1869\n",
      "eopch: 2/2, step 465/600, loss = 0.1188\n",
      "eopch: 2/2, step 470/600, loss = 0.1727\n",
      "eopch: 2/2, step 475/600, loss = 0.2199\n",
      "eopch: 2/2, step 480/600, loss = 0.4462\n",
      "eopch: 2/2, step 485/600, loss = 0.3832\n",
      "eopch: 2/2, step 490/600, loss = 0.2235\n",
      "eopch: 2/2, step 495/600, loss = 0.2435\n",
      "eopch: 2/2, step 500/600, loss = 0.1886\n",
      "eopch: 2/2, step 505/600, loss = 0.2450\n",
      "eopch: 2/2, step 510/600, loss = 0.2528\n",
      "eopch: 2/2, step 515/600, loss = 0.3482\n",
      "eopch: 2/2, step 520/600, loss = 0.2806\n",
      "eopch: 2/2, step 525/600, loss = 0.0687\n",
      "eopch: 2/2, step 530/600, loss = 0.2042\n",
      "eopch: 2/2, step 535/600, loss = 0.1913\n",
      "eopch: 2/2, step 540/600, loss = 0.1756\n",
      "eopch: 2/2, step 545/600, loss = 0.1724\n",
      "eopch: 2/2, step 550/600, loss = 0.2207\n",
      "eopch: 2/2, step 555/600, loss = 0.1416\n",
      "eopch: 2/2, step 560/600, loss = 0.0941\n",
      "eopch: 2/2, step 565/600, loss = 0.1451\n",
      "eopch: 2/2, step 570/600, loss = 0.1832\n",
      "eopch: 2/2, step 575/600, loss = 0.1200\n",
      "eopch: 2/2, step 580/600, loss = 0.2777\n",
      "eopch: 2/2, step 585/600, loss = 0.1548\n",
      "eopch: 2/2, step 590/600, loss = 0.2679\n",
      "eopch: 2/2, step 595/600, loss = 0.2157\n",
      "eopch: 2/2, step 600/600, loss = 0.1785\n",
      "accuracy = 95.17333333333333\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no sigmoid required as CrossEntropyLosss contain sigmoid\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # forward pass\n",
    "        images = images.reshape((batch_size, -1)).to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model(images)\n",
    "        l = loss(y_pred, labels)\n",
    "        \n",
    "        # zero the grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        l.backward()\n",
    "        \n",
    "        # update weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%5 == 0:\n",
    "            print(f'eopch: {epoch+1}/{EPOCHS}, step {i+1}/{n_total_steps}, loss = {l:.4f}')\n",
    "            \n",
    "# calculate the accuracy\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape((batch_size, -1)).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        \n",
    "        # torch.max return value, index\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.*n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
