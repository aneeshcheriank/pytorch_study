{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9hROfC7X2vyU8qT/KEi8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeshcheriank/pytorch_study/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.utils.data.DataLoader: an iterable around the Dataset\n",
        "- torch.utils.data.DataSet: stores the samples and their currespoinding labels"
      ],
      "metadata": {
        "id": "LsC9JIorii_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wD5vj6Wkh_tm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [torchvision datasets](https://pytorch.org/vision/stable/datasets.html)"
      ],
      "metadata": {
        "id": "Udqkf5LijH7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the training data from open datasets\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root='data' # the folder in which the data is stored\n",
        "    , train=True # training data\n",
        "    , download=True # if the data is not present it will download the data\n",
        "    , transform = ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "testing_data = datasets.FashionMNIST(\n",
        "    root='data' # the folder in which the data is stored\n",
        "    , train=False # labeled data\n",
        "    , download=True\n",
        "    , transform = ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "gtyeaqIwiezB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
        "\n",
        "x, y = iter(train_dataloader).next()\n",
        "print(f'shape of x: {x.shape}')\n",
        "print(f'shape of x: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfiDXWxfkLP6",
        "outputId": "b674c0e1-6b0e-488c-d4e4-e965062738ba"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x: torch.Size([64, 1, 28, 28])\n",
            "shape of x: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the training device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pcAneCJlB43",
        "outputId": "637761bd-0b7a-43a1-80ab-baaa0e1ea8e7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer and loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) #pass model_parameters and learning rate"
      ],
      "metadata": {
        "id": "a9e7oRIEnXva"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train() # why?\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # compute the loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y) # predicted, actual in tf it is the opposite\n",
        "\n",
        "    # Backpropogation\n",
        "    optimizer.zero_grad() # to clear the optimzier\n",
        "    loss.backward()\n",
        "    optimizer.step() # apply the gradients to the trainable weights\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f'loss: {loss} [{current}/{size}]')\n"
      ],
      "metadata": {
        "id": "zQH9pebDoQa8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- model.train()\n",
        "  - dropouts and batchnormaliztion behaves differently during training and evaluation\n",
        "  - so the model should know the training and evaluation\n",
        "  - hence there is model.train() and model.eval()"
      ],
      "metadata": {
        "id": "D6BJ7aP_WM0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f'Test Error:\\n Accruacy: {100*correct}% Avg loss: {test_loss}\\n')"
      ],
      "metadata": {
        "id": "j2qcL6xMqXLe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss, optimizer)\n",
        "    test(test_dataloader, model, loss, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk7lieq2C5Ft",
        "outputId": "924cac8b-8206-4202-ee6a-6794961ed8a1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.2985124588012695 [0/60000]\n",
            "loss: 2.288897752761841 [6400/60000]\n",
            "loss: 2.2618870735168457 [12800/60000]\n",
            "loss: 2.2628700733184814 [19200/60000]\n",
            "loss: 2.240830421447754 [25600/60000]\n",
            "loss: 2.202150583267212 [32000/60000]\n",
            "loss: 2.2237823009490967 [38400/60000]\n",
            "loss: 2.1805951595306396 [44800/60000]\n",
            "loss: 2.187969923019409 [51200/60000]\n",
            "loss: 2.152620315551758 [57600/60000]\n",
            "Test Error:\n",
            " Accruacy: 41.760000000000005% Avg loss: 2.1443387459797463\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.1573503017425537 [0/60000]\n",
            "loss: 2.149087429046631 [6400/60000]\n",
            "loss: 2.0751163959503174 [12800/60000]\n",
            "loss: 2.102557897567749 [19200/60000]\n",
            "loss: 2.041294574737549 [25600/60000]\n",
            "loss: 1.978084683418274 [32000/60000]\n",
            "loss: 2.012072801589966 [38400/60000]\n",
            "loss: 1.9211896657943726 [44800/60000]\n",
            "loss: 1.9384064674377441 [51200/60000]\n",
            "loss: 1.8696942329406738 [57600/60000]\n",
            "Test Error:\n",
            " Accruacy: 55.08% Avg loss: 1.8555260441105836\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.8898545503616333 [0/60000]\n",
            "loss: 1.8639912605285645 [6400/60000]\n",
            "loss: 1.721123218536377 [12800/60000]\n",
            "loss: 1.7819395065307617 [19200/60000]\n",
            "loss: 1.670461893081665 [25600/60000]\n",
            "loss: 1.6168725490570068 [32000/60000]\n",
            "loss: 1.6451994180679321 [38400/60000]\n",
            "loss: 1.5420713424682617 [44800/60000]\n",
            "loss: 1.575527310371399 [51200/60000]\n",
            "loss: 1.4766490459442139 [57600/60000]\n",
            "Test Error:\n",
            " Accruacy: 58.5% Avg loss: 1.4873914559176014\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.555098533630371 [0/60000]\n",
            "loss: 1.5306682586669922 [6400/60000]\n",
            "loss: 1.3579667806625366 [12800/60000]\n",
            "loss: 1.4531443119049072 [19200/60000]\n",
            "loss: 1.3354488611221313 [25600/60000]\n",
            "loss: 1.3248026371002197 [32000/60000]\n",
            "loss: 1.3442164659500122 [38400/60000]\n",
            "loss: 1.270928144454956 [44800/60000]\n",
            "loss: 1.309376835823059 [51200/60000]\n",
            "loss: 1.214362621307373 [57600/60000]\n",
            "Test Error:\n",
            " Accruacy: 61.339999999999996% Avg loss: 1.2395406714670218\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.3148047924041748 [0/60000]\n",
            "loss: 1.307185411453247 [6400/60000]\n",
            "loss: 1.1247668266296387 [12800/60000]\n",
            "loss: 1.2496179342269897 [19200/60000]\n",
            "loss: 1.125488042831421 [25600/60000]\n",
            "loss: 1.14284348487854 [32000/60000]\n",
            "loss: 1.166455864906311 [38400/60000]\n",
            "loss: 1.1079767942428589 [44800/60000]\n",
            "loss: 1.1480077505111694 [51200/60000]\n",
            "loss: 1.065639853477478 [57600/60000]\n",
            "Test Error:\n",
            " Accruacy: 63.370000000000005% Avg loss: 1.0891543102871841\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuuBkgDDX6b",
        "outputId": "934f7702-02b1-4ec0-fecd-73b7480dfda7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n",
        "print(\"saved the pytorch model to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt5vWK2oE1cz",
        "outputId": "c171f245-9466-4bf9-d20e-300000f6cab8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved the pytorch model to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork() # need to create a structure\n",
        "model.load_state_dict(torch.load('model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdCcXcj2UmU1",
        "outputId": "6f77b5de-6017-47e0-8478-a5913d36e54a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = testing_data[0][0], testing_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fofaFDuXU4UW",
        "outputId": "c750ea51-f756-46f5-97e8-f0801a21badb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}